{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0fb2c00-5f86-4e04-bc1c-db96cb136d93",
   "metadata": {},
   "source": [
    "# # MM pipeline: Run the DeLTA tracking model over all folders\n",
    "\n",
    "This has originally been provided by Owen O'Connor and modified by Julian Baer to work with the pipeline to analyse mother machine images analysed with JB's pipeline.\n",
    "The delta post-processing script that creates a nice .csv that I import into R for analysis was provided by Simon van Vliet. The outputs are as followed:\n",
    "\n",
    "In the data frame we now have the following lineage information:\n",
    "\n",
    "- `id_seg`: the ordinal lineage id assigned by delta (contains cell+offspring), this index (offset by 1) in label image. Don't use this unless you need to interface wit label image\n",
    "- `id_cell`: a unique id for each cell, from birth to division. Always use this to access cell lineages.\n",
    "- `id_par`: the `id_cell` number of a cell's parent\n",
    "- `id_colony`: each cell in first frame is assigned a unique `id_colony` which is shared with all it's offspring. (e.g. use this to separate different colonies)\n",
    "- `id_d1`: the `id_cell` number of a cell's first offspring (old-pole)\n",
    "- `id_d2`: the `id_cell` number of a cell's second offspring (new-pole)\n",
    "- `id_sib`: the `id_cell` number of a cell's sibling\n",
    "- `generation`: cell generation: 0 for cells present in first frame, 1 for first generation of offspring, etc.\n",
    "- `age`: frame number relative to birth of cell, i.e. it goes from 0:T where T is life time of cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb71ca2-30ea-4214-9d97-75e5df8b504b",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Specify paths and variables in the s0_writeconfig.mat file:\n",
    "- `deltapath`  as I use a locally modified delta version that is not installed via conda or pip, I append the path to where I have that delta package stored and load from there. Please modify accordingly!! This modified version is included in the github repo.\n",
    "- `configpath` DeLTA uses it's own seperate config file. This is the path to the storage of this config file. This needs to point to the tracking model (hdf5) file. This hdf5 is large and not included in the github repo. You can download my mother-machine 2D model for cocci here: LINK\n",
    "- `configname` name of the DeLTA config file\n",
    "- `imageprototype` structure of the image naming scheme, all the ID numbers in it and the number format of the IDs\n",
    "- `orderprototype` corresponding structure of IDs. *p* = position; *c* = color channel; *t* = frame\n",
    "- `image_heigth` and `image_width` pad images to this size if they're smaller. 256x256 is also the size the tracking model has been trained for and it cannot be smaller than that. Never tried with bigger images... Your task! :)\n",
    "- `cropimages` a parameter in the creation of the position object of delta. No idea if this has an effect on tracking or only on their segmentation model\n",
    "- `driftcor` a parameter in the creation of the posiiton object of delta. Maybe you can use that?\n",
    "- `saveformats` you can save movies for the tracking, data in pickle or .mat formats (native delta outputs). Additionally, I anyway save a .csv for each movie with some (for me) easier-to-read formating.\n",
    "- `clearsaves` If True, delete all detected delta output before attempting to track. Useful if you're troubleshooting and want to make sure all previous attempts are erased\n",
    "- `savemovie` If True, save the Delta movie\n",
    "- `savemoviefreq` frequency of movie saving.\n",
    "- `features_list` delta features to track.\n",
    "\n",
    "\n",
    "\n",
    "### Load main config file. Adapt directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "070881ec-d800-4c7e-bc95-27538393d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "configdir = 'G://GitHub/microfluidics-image-processing/MM_pipeline';\n",
    "mainconfigname = 'config_example_matched';\n",
    "\n",
    "if not mainconfigname.endswith('.json'):\n",
    "    mainconfigname += '.json'\n",
    "    \n",
    "if not configdir.endswith('/'):\n",
    "    configdir += '/'\n",
    "\n",
    "import json\n",
    "# Read JSON data\n",
    "with open(configdir+mainconfigname, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Assign each key-value pair as a variable\n",
    "for key, value in data.items():\n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66bb80-51ac-4f22-880a-c6c36abed36f",
   "metadata": {},
   "source": [
    "### Check if the DeLTA config path is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d3281e-6379-4255-be56-293c55062f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G://GitHub/microfluidics-image-processing/delta_config/\n"
     ]
    }
   ],
   "source": [
    "print(configpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797dde5-4570-47a2-b172-982691e595fa",
   "metadata": {},
   "source": [
    "### Load various packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0e9480-8e2f-45e6-aea6-e06084b0c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from: G:\\GitHub\\microfluidics-image-processing\\delta_config\\config_2D_azimages.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import sys\n",
    "import pathlib\n",
    "sys.path.append(deltapath)\n",
    "import glob\n",
    "\n",
    "import delta\n",
    "import delta.utilities as utils\n",
    "from delta.utilities import cfg\n",
    "from delta.delta_postprocess import delta_to_df #contains all the code to convert delta object\n",
    "\n",
    "#import napari\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.segmentation import clear_border\n",
    "from scipy import ndimage \n",
    "import os\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "def to_str(posixpath):\n",
    "    return str(posixpath.resolve())\n",
    "\n",
    "cfg.load_config(to_str(pathlib.Path(configpath + configname)))\n",
    "cfg.save_format = saveformats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b395bf-e926-408f-9083-16c03e618347",
   "metadata": {},
   "source": [
    "### Load in meta file and display head. Check if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512d082d-ff26-413c-8c63-534dbb7d93db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>replicate</th>\n",
       "      <th>chip</th>\n",
       "      <th>pos</th>\n",
       "      <th>channel</th>\n",
       "      <th>Process</th>\n",
       "      <th>replicate2</th>\n",
       "      <th>Process2</th>\n",
       "      <th>rep2startdifferencemin</th>\n",
       "      <th>rep2firstframe</th>\n",
       "      <th>...</th>\n",
       "      <th>StageY</th>\n",
       "      <th>PxinUmX</th>\n",
       "      <th>PxinUmY</th>\n",
       "      <th>register</th>\n",
       "      <th>stardist</th>\n",
       "      <th>stardist_data</th>\n",
       "      <th>stardist_data_cor</th>\n",
       "      <th>stardist_fails</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_fails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.08.2024</td>\n",
       "      <td>r02</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-36507.72605</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.08.2024</td>\n",
       "      <td>r02</td>\n",
       "      <td>c1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-37249.40072</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.08.2024</td>\n",
       "      <td>r04</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1784</td>\n",
       "      <td>r04b</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38615.71153</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaT</td>\n",
       "      <td>r06</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2075</td>\n",
       "      <td>r06b</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-37305.10401</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaT</td>\n",
       "      <td>r06</td>\n",
       "      <td>c2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2093</td>\n",
       "      <td>r06b</td>\n",
       "      <td>2169.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-37185.52962</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date replicate chip  pos  channel  Process replicate2  Process2  \\\n",
       "0  22.08.2024       r02   c1    1        2     1108        NaN       NaN   \n",
       "1  22.08.2024       r02   c1    2        3     1113        NaN       NaN   \n",
       "2  29.08.2024       r04   c1    1        2     1784       r04b    1847.0   \n",
       "3         NaT       r06   c1    1        3     2075       r06b    2151.0   \n",
       "4         NaT       r06   c2    2        1     2093       r06b    2169.0   \n",
       "\n",
       "   rep2startdifferencemin  rep2firstframe  ...       StageY  PxinUmX PxinUmY  \\\n",
       "0                     NaN             NaN  ... -36507.72605    0.065   0.065   \n",
       "1                     NaN             NaN  ... -37249.40072    0.065   0.065   \n",
       "2                   145.0            41.0  ... -38615.71153    0.065   0.065   \n",
       "3                    65.0            10.0  ... -37305.10401    0.065   0.065   \n",
       "4                    65.0            10.0  ... -37185.52962    0.065   0.065   \n",
       "\n",
       "   register  stardist  stardist_data  stardist_data_cor  stardist_fails  \\\n",
       "0      Done      Done            NaN                NaN             NaN   \n",
       "1      Done      Done            NaN                NaN             NaN   \n",
       "2      Done      Done            NaN                NaN             NaN   \n",
       "3      Done      Done            NaN                NaN             NaN   \n",
       "4      Done      Done            NaN                NaN             NaN   \n",
       "\n",
       "   delta delta_fails  \n",
       "0    NaN         NaN  \n",
       "1    NaN         NaN  \n",
       "2    NaN         NaN  \n",
       "3    NaN         NaN  \n",
       "4    NaN         NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(os.path.join(masterdir,metacsv))\n",
    "replicates = meta.replicate.unique()\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dcf615-3e9d-44cf-9198-bba8b4344340",
   "metadata": {},
   "source": [
    "# The actual tracking loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c2b6b-8204-4824-83f3-d05288b592af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r09, Pos 01:   0%|                                                                              | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\conda_envs\\jbdelta\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From G:\\conda_envs\\jbdelta\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r09, Pos 01:  15%|██████████▎                                                           | 4/27 [01:00<05:51, 15.28s/it]"
     ]
    }
   ],
   "source": [
    "# check number of channels and add intensity quantification to features list\n",
    "if n_channel > 1:\n",
    "    features_list.append(\"fluo1\")\n",
    "\n",
    "if n_channel > 2:\n",
    "    features_list.append(\"fluo2\")\n",
    "\n",
    "# Initialize counter\n",
    "saved_movies = 0\n",
    "\n",
    "# Create a blank reference image based on drift correction setting\n",
    "new_image_width = image_width\n",
    "new_image_height = image_height\n",
    "ref = None if driftcor else np.zeros((image_height, image_width), dtype=np.float32)\n",
    "\n",
    "# Process each row in the meta file\n",
    "for i in range(meta.shape[0]):\n",
    "    fails = []  # To record any failures\n",
    "    \n",
    "    \n",
    "    # Skip conditions\n",
    "    row = meta.iloc[i]\n",
    "    if row['delta'] == 'Done' or row['Exclude'] in ['excl', 'skip'] or row['stardist'] != 'Done' or row['dt'] > 3 or isinstance(row['replicate2'], str):\n",
    "        continue\n",
    "        \n",
    "    # Setup directories\n",
    "    main_folder = os.path.join(masterdir, savedirname, row['replicate'], 'Chambers')\n",
    "    save_directory = os.path.join(main_folder, deltasavename)\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    # Clear saved files if needed\n",
    "    if clearsaves:\n",
    "        for pattern in ['*Pos{}*mp4', '*Pos{}*csv']:\n",
    "            for file in Path(save_directory).glob(pattern.format(str(row['pos']).zfill(2))):\n",
    "                os.remove(file)\n",
    "\n",
    "    # Current position folder\n",
    "    curr_dir = os.path.join(main_folder, f'Pos{round(row[\"pos\"]):02d}')\n",
    "\n",
    "    # List all image folders\n",
    "    chamber_folders = [f.path for f in os.scandir(curr_dir) if f.is_dir() and 'Chamb' in f.name]\n",
    "\n",
    "\n",
    "    # Process each chamber folder\n",
    "    for chami, chamber_folder in enumerate(tqdm(chamber_folders, desc=f\"{row['replicate']}, Pos {round(row['pos']):02d}\")):\n",
    "        try:\n",
    "            # Initialize reader and position object\n",
    "            reader = delta.utils.xpreader(Path(curr_dir), fileorder=orderprototype, prototype=imageprototype)\n",
    "            position_nb = chami\n",
    "\n",
    "            # rois set to 0\n",
    "            rois_nb = 0\n",
    "\n",
    "            #print(chamber_folders[chami])\n",
    "            # get list of all images\n",
    "            unprocessed = sorted(glob.glob((chamber_folders[chami]) + \"/*.tif\"))\n",
    "\n",
    "            # create the delta position object\n",
    "            pos = delta.pipeline.Position(\n",
    "                position_nb=position_nb,\n",
    "                reader=reader,\n",
    "                models=delta.utils.loadmodels(),\n",
    "                drift_correction=driftcor,\n",
    "                crop_windows=cropimages\n",
    "                )\n",
    "\n",
    "            # features to extract\n",
    "            features = tuple(features_list)\n",
    "\n",
    "            # run delta pre-processing                       \n",
    "            pos.preprocess(rotation_correction=delta.config.rotation_correction, reference = ref)\n",
    "\n",
    "\n",
    "            # get list of frames/timepoints and go over all images and segmentation files\n",
    "            # to pad them to 256x256.\n",
    "            # for the segmentation images, transform them to binary masks and make sure\n",
    "            # that there's always a gap between cells\n",
    "            frames = [f for f in range(pos.reader.timepoints)]\n",
    "            for trans_frameN in unprocessed:\n",
    "                # read in current image\n",
    "                trans_frame = cv2.imread(str(trans_frameN),cv2.IMREAD_ANYDEPTH)\n",
    "                # scale it to [0, 1]\n",
    "                trans_frame = utils.rangescale(trans_frame, rescale=(0, 1))\n",
    "                # get old image size\n",
    "                old_image_height, old_image_width = trans_frame.shape\n",
    "\n",
    "                # if it is bigger, crop it. Not sure if that works well..?\n",
    "                if new_image_height<old_image_height:\n",
    "                    dif = old_image_height - new_image_height\n",
    "                    crop_img = trans_frame[dif:old_image_height, :]\n",
    "                else:\n",
    "                    crop_img = trans_frame\n",
    "                # reevaluate size\n",
    "                old_image_height, old_image_width = crop_img.shape\n",
    "                # init an empty image\n",
    "                color = 0\n",
    "                result = np.full((new_image_height,new_image_width), color, dtype=np.float32)\n",
    "                # compute center offset\n",
    "                x_center = (new_image_width - old_image_width) // 2\n",
    "                y_center = (new_image_height - old_image_height) // 2\n",
    "                # copy img image into center of result image\n",
    "                result[y_center:y_center+old_image_height, \n",
    "                       x_center:x_center+old_image_width] = crop_img\n",
    "                # append these images to the position object\n",
    "                pos.rois[rois_nb].img_stack.append(result)\n",
    "\n",
    "            # same for the segmentation images\n",
    "            seg_fps = sorted(glob.glob((chamber_folders[chami] + '/seg_sd2') + \"/*.tif\"))\n",
    "            for seg_fp in seg_fps:\n",
    "                # read image\n",
    "                seg = cv2.imread(str(seg_fp),cv2.IMREAD_ANYDEPTH)\n",
    "                # get size, crop if needed\n",
    "                old_image_height, old_image_width = seg.shape\n",
    "                if new_image_height<old_image_height:\n",
    "                    dif = old_image_height - new_image_height\n",
    "                    crop_img = seg[dif:old_image_height, :]\n",
    "                else:\n",
    "                    crop_img = seg\n",
    "\n",
    "                old_image_height, old_image_width = crop_img.shape\n",
    "                color = 0\n",
    "                # format new image\n",
    "                if (np.amax(crop_img)>0):\n",
    "                    crop_img *= (255.0/crop_img.max())\n",
    "                crop_img = crop_img.astype('int32')\n",
    "\n",
    "                # get the boundaries of labels, set these to 0\n",
    "                mask = skimage.segmentation.find_boundaries(crop_img, connectivity=1, mode='outer', background=0)\n",
    "                crop_img[mask] = 0\n",
    "\n",
    "                # remove cells that touch upper and lower parts of the image. These are difficult to track\n",
    "                # you may remove that part\n",
    "                bordermask = np.full((old_image_height,old_image_width), 1, dtype=np.float32)\n",
    "                bordermask[:,0:2] = 0\n",
    "                bordermask[:,-3:-1] = 0\n",
    "                bordermask = bordermask.astype(bool)\n",
    "                crop_img = clear_border(np.array(crop_img, dtype=bool), mask = bordermask)\n",
    "\n",
    "                # paste that cleaned up binary image into a new image with correct size\n",
    "                result = np.full((new_image_height,new_image_width), color, dtype=np.float32)\n",
    "                # compute center offset\n",
    "                x_center = (new_image_width - old_image_width) // 2\n",
    "                y_center = (new_image_height - old_image_height) // 2\n",
    "                # copy img image into center of result image\n",
    "                result[y_center:y_center+old_image_height, \n",
    "                   x_center:x_center+old_image_width] = crop_img\n",
    "\n",
    "                result = np.array(result, dtype=bool)\n",
    "                # append it into the seg_stack of the position object\n",
    "                pos.rois[rois_nb].seg_stack.append(result.astype(np.uint8))\n",
    "\n",
    "            # finally, we track!!\n",
    "            pos.track(list(range(reader.timepoints)))\n",
    "            # and extract features\n",
    "            pos.features(frames=frames, features=features)\n",
    "            # extract lineage object. If this is not empty, save .csv files\n",
    "            lin = pos.rois[0].lineage\n",
    "            if len(lin.cells)>0:\n",
    "                df = delta_to_df(pos)\n",
    "                save_name = save_directory + '/' + 'Pos' + str(round(meta.pos[i])).zfill(2) + chamber_folders[chami][-7:]\n",
    "                #print(save_name)\n",
    "                df.to_csv(save_name + '.csv' , index=False)\n",
    "                if savemovie:\n",
    "                    if saved_movies == savemoviefreq:\n",
    "                        try:\n",
    "                            pos.save(\n",
    "                            filename=save_name,\n",
    "                            frames=frames,\n",
    "                            save_format=cfg.save_format,\n",
    "                            )\n",
    "                            saved_movies = 0\n",
    "                        except Exception as e:\n",
    "                            # Log any errors encountered during processing\n",
    "                            fails.append(f\"Error movie export {curr_dir},: {e}\")\n",
    "                    saved_movies +=1\n",
    "        except Exception as e:\n",
    "            # Log any errors encountered during processing\n",
    "            fails.append(f\"chamber {chami}: {e}\")\n",
    "\n",
    "    # re-read meta file (this ensures correct status as I run multiple scripts simultaneously that all read and write into it)\n",
    "    meta = pd.read_csv(os.path.join(masterdir,metacsv))\n",
    "    \n",
    "    # update status and save\n",
    "    meta.loc[i, ('delta')] = 'Done'\n",
    "    if fails:\n",
    "        meta.at[i, 'delta_fails'] = '; '.join(fails)\n",
    "        \n",
    "    meta.to_csv(os.path.join(masterdir,metacsv), index = False)\n",
    "    today = date.today()\n",
    "    meta.to_csv(os.path.join(masterdir,metacsv+'_' + today.strftime(\"%Y-%m-%d\") + '.csv'), index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c5d51-b123-4adf-be4b-8300ea413767",
   "metadata": {},
   "source": [
    "# You are at the end!!\n",
    "\n",
    "Now, have fun exploring your data with whatever other sofware you like :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cebad86-6e3c-43a3-8f45-b6c31f6ca028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f3bf6-ff0a-411a-816a-9427efbf1ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
