{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55d75ff-0bbf-4266-aef9-f3e71ae006f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# MM pipeline: Run the StarDist2D segmentation model over all folders\n",
    "\n",
    "This notebook loads a pretrained StarDist2D segmentation model and applies the segmentation prediction on all folders within the masterfolder mainf (defined in 2nd code cell). Only microscopy chamber data containing folders should be within mainf. The segmentation is applied onto all images that end with *_PH.tif* and the segmentation image is saved into a newly created folder within each image folder named *seg_sd2*. For the moment, it assumes single-page tif files and saves single-page tif files with the exact same name as the input image used for segmentation prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be194b4",
   "metadata": {},
   "source": [
    "### Load main config file. Adapt directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6037ab35-db6c-4993-95fe-2384b76475ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:38:46.034578900Z",
     "start_time": "2026-02-10T18:38:45.966084700Z"
    }
   },
   "outputs": [],
   "source": [
    "configdir = 'G://GitHub/microfluidics-image-processing/MM_pipeline';\n",
    "\n",
    "# uncomment the one running:\n",
    "#mainconfigname = 'config_example_mixed';\n",
    "mainconfigname = 'config_example_matched';\n",
    "\n",
    "\n",
    "if not mainconfigname.endswith('.json'):\n",
    "    mainconfigname += '.json'\n",
    "    \n",
    "if not configdir.endswith('/'):\n",
    "    configdir += '/'\n",
    "\n",
    "import json\n",
    "# Read JSON data\n",
    "with open(configdir+mainconfigname, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Assign each key-value pair as a variable\n",
    "for key, value in data.items():\n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270a2bc-943c-444b-9229-11bb2c1c965f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load various packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8362889-58a4-41ef-8062-80dbeb95f539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:38:56.266827300Z",
     "start_time": "2026-02-10T18:38:51.428552800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread, imwrite\n",
    "from datetime import datetime\n",
    "from csbdeep.utils import Path, normalize\n",
    "from skimage.measure import regionprops_table\n",
    "from skimage import io\n",
    "from skimage import segmentation\n",
    "from skimage import color\n",
    "from stardist.matching import matching_dataset\n",
    "from stardist import fill_label_holes, random_label_cmap, relabel_image_stardist, calculate_extents, gputools_available, _draw_polygons\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import re\n",
    "from pathlib import Path\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "def add_prefix(props, prefix):\n",
    "    return {f\"{prefix}_{key}\" if 'intensity' in key else key: value for key, value in props.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ae6e8-8712-4f38-9056-05fd1c397602",
   "metadata": {},
   "source": [
    "### Check if GPU can be accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fbcd94-85b0-4361-8002-31aa57e2171a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:38:59.294870500Z",
     "start_time": "2026-02-10T18:38:58.785925200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gputools_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17582b-56ed-4f81-b42c-04215b86b637",
   "metadata": {},
   "source": [
    "### Load in meta file and display head. Check if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5843fccb-8d7a-40ea-919c-2c4e49fc6d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:39:01.923712800Z",
     "start_time": "2026-02-10T18:39:01.855059800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I://Julian/agr_rev_matched/sharing/matched\\shared_matched_meta_processing.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>replicate</th>\n",
       "      <th>chip</th>\n",
       "      <th>pos</th>\n",
       "      <th>channel</th>\n",
       "      <th>Process</th>\n",
       "      <th>replicate2</th>\n",
       "      <th>Process2</th>\n",
       "      <th>rep2startdifferencemin</th>\n",
       "      <th>rep2firstframe</th>\n",
       "      <th>...</th>\n",
       "      <th>StageY</th>\n",
       "      <th>PxinUmX</th>\n",
       "      <th>PxinUmY</th>\n",
       "      <th>register</th>\n",
       "      <th>stardist</th>\n",
       "      <th>stardist_data</th>\n",
       "      <th>stardist_data_cor</th>\n",
       "      <th>stardist_fails</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_fails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaT</td>\n",
       "      <td>r10</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3818</td>\n",
       "      <td>r10b</td>\n",
       "      <td>3931.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-49316.40331</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaT</td>\n",
       "      <td>r11</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4014</td>\n",
       "      <td>r11b</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-43571.36198</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaT</td>\n",
       "      <td>r11</td>\n",
       "      <td>c1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4026</td>\n",
       "      <td>r11b</td>\n",
       "      <td>4058.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-39732.80679</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaT</td>\n",
       "      <td>r11</td>\n",
       "      <td>c1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4036</td>\n",
       "      <td>r11b</td>\n",
       "      <td>4068.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-37792.56431</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaT</td>\n",
       "      <td>r13</td>\n",
       "      <td>c1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-37932.46000</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date replicate chip  pos  channel  Process replicate2  Process2  \\\n",
       "15  NaT       r10   c1    1        2     3818       r10b    3931.0   \n",
       "16  NaT       r11   c1    1        1     4014       r11b    4046.0   \n",
       "17  NaT       r11   c1    2        3     4026       r11b    4058.0   \n",
       "18  NaT       r11   c1    3        4     4036       r11b    4068.0   \n",
       "19  NaT       r13   c1    4        6     2567        NaN       NaN   \n",
       "\n",
       "    rep2startdifferencemin  rep2firstframe  ...       StageY  PxinUmX PxinUmY  \\\n",
       "15                   228.0            37.0  ... -49316.40331    0.065   0.065   \n",
       "16                    50.0             8.0  ... -43571.36198    0.065   0.065   \n",
       "17                    50.0             8.0  ... -39732.80679    0.065   0.065   \n",
       "18                    50.0             8.0  ... -37792.56431    0.065   0.065   \n",
       "19                     NaN             NaN  ... -37932.46000    0.065   0.065   \n",
       "\n",
       "    register  stardist  stardist_data  stardist_data_cor  stardist_fails  \\\n",
       "15      Done       NaN            NaN                NaN             NaN   \n",
       "16      Done       NaN            NaN                NaN             NaN   \n",
       "17      Done       NaN            NaN                NaN             NaN   \n",
       "18      Done       NaN            NaN                NaN             NaN   \n",
       "19      Done       NaN            NaN                NaN             NaN   \n",
       "\n",
       "    delta delta_fails  \n",
       "15    NaN         NaN  \n",
       "16    NaN         NaN  \n",
       "17    NaN         NaN  \n",
       "18    NaN         NaN  \n",
       "19    NaN         NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.path.join(masterdir,metacsv))\n",
    "meta = pd.read_csv(os.path.join(masterdir,metacsv), dtype={'stardist': str})\n",
    "replicates = meta.replicate.unique()\n",
    "meta.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a362e",
   "metadata": {},
   "source": [
    "### Load stardist model\n",
    "Here, the model is loaded. You need to specify the dir which contains a folder named *stardist* in the config file. This *stardist* folder needs to contain the files *weigths_best.h5* as well as the *config.json* and optionally the *thresholds.json*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3713b5-93e4-4d12-8e15-ace7422c52e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:41:08.664371200Z",
     "start_time": "2026-02-10T18:39:04.580356700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G://GitHub/microfluidics-image-processing/stardist_models/mm\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.586968, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "print(stardistmodeldir)\n",
    "model = StarDist2D(None, name='stardist', basedir=stardistmodeldir)\n",
    "axis_norm = (0,1)   # normalize channels independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a983f-591d-4329-9de0-f7351b1d17e3",
   "metadata": {},
   "source": [
    "### Define regionprops parameters. You could add more if you want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a8cea5-1872-4fcf-98d2-804f99a854fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:47:09.838175900Z",
     "start_time": "2026-02-10T18:47:09.793126100Z"
    }
   },
   "outputs": [],
   "source": [
    "if n_channel>1:\n",
    "    flims = True;\n",
    "    prop_list = ['label', \n",
    "                'area', 'centroid', \n",
    "                'axis_major_length', 'axis_minor_length',\n",
    "                 'eccentricity',\n",
    "                'intensity_mean', 'intensity_max']\n",
    "else:\n",
    "    flims = False;\n",
    "    prop_list = ['label', \n",
    "                'area', 'centroid', \n",
    "                'axis_major_length', 'axis_minor_length',\n",
    "                 'eccentricity'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31f0d9-c131-4c66-9b49-57d381335eb7",
   "metadata": {},
   "source": [
    "### Limit GPU RAM usage by StarDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbec354f-3d21-46cd-ad68-12021a62494e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:47:14.422765200Z",
     "start_time": "2026-02-10T18:47:14.369218900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "# adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "limit_gpu_memory(fraction=ramlimit, total_memory=ramsize)\n",
    "# alternatively, try this:\n",
    "# limit_gpu_memory(None, allow_growth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c295a-9117-459c-a490-959495b3665f",
   "metadata": {},
   "source": [
    "## Main segmentation loop\n",
    "This loop goes over each row in the meta file which is marked with completed preprocessing (Progress == 'Done') and applies the StarDist segmentation model to each position/chamber iteratively. For the moment, not paralellized but could probably benefit from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6820e7d4-cfce-424b-9f53-aaa823a050ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:47:17.895160300Z",
     "start_time": "2026-02-10T18:47:17.872149900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Patch Keras model's predict to always use verbose=0\n",
    "orig_predict = model.keras_model.predict\n",
    "def predict_no_verbose(*args, **kwargs):\n",
    "    kwargs['verbose'] = 0\n",
    "    return orig_predict(*args, **kwargs)\n",
    "model.keras_model.predict = predict_no_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cfbbe4-bdc9-442a-a1eb-226439f5fcfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:47:19.580915700Z",
     "start_time": "2026-02-10T18:47:19.549771200Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper to robustly extract trailing integer from a path basename\n",
    "def extract_trailing_int_from_basename(path):\n",
    "    name = os.path.basename(path)\n",
    "    m = re.search(r'(\\d+)$', name)\n",
    "    return int(m.group(1)) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852a07c-a070-4f8e-b21e-df10d0fc29e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T19:13:45.725516400Z",
     "start_time": "2026-02-10T18:47:21.827825400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r07, Pos 01:   6%|████▍                                                                 | 3/48 [01:10<17:25, 23.23s/it]"
     ]
    }
   ],
   "source": [
    "for i in range(0, meta.shape[0]):\n",
    "    # reload metadata each iteration if you need the file updated by others,\n",
    "    # otherwise you can read once before the loop for speed.\n",
    "    meta = pd.read_csv(os.path.join(masterdir, metacsv), dtype={'stardist': str, 'stardist_data': str})\n",
    "\n",
    "    if meta.loc[i, 'stardist'] == 'Done' or meta.loc[i, 'Exclude'] == 'excl' or not meta.loc[i, ('register')] == 'Done':\n",
    "        continue\n",
    "\n",
    "    main_folder = os.path.join(masterdir, savedirname, meta.replicate[i], 'Chambers')\n",
    "    save_directory = os.path.join(main_folder, 'stardist2')\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    current_directory = os.path.join(main_folder, f'Pos{str(meta.pos[i]).zfill(2)}')\n",
    "    if not os.path.exists(current_directory):\n",
    "        print(current_directory + ' not found')\n",
    "        continue\n",
    "\n",
    "    chambf = [f.path for f in os.scandir(current_directory) if f.is_dir()]\n",
    "    chambf = [k for k in chambf if 'Chamb' in k]\n",
    "\n",
    "    fails = []\n",
    "\n",
    "    for chambi in tqdm(range(0, len(chambf)), desc=meta.replicate[i] + ', Pos ' + str(meta.pos[i]).zfill(2)):\n",
    "        inputs_folder = chambf[chambi]\n",
    "        outputs_folder = os.path.join(inputs_folder, \"seg_sd2\")\n",
    "        os.makedirs(outputs_folder, exist_ok=True)\n",
    "        for file in Path(outputs_folder).glob('*tif'):\n",
    "            os.remove(file)\n",
    "\n",
    "        images = sorted(Path(inputs_folder).glob('*Ch1*tif'))\n",
    "        if flims:\n",
    "            images_fl = sorted(Path(inputs_folder).glob('*Ch2*tif'))\n",
    "            if n_channel > 2:\n",
    "                images_fl2 = sorted(Path(inputs_folder).glob('*Ch3*tif'))\n",
    "\n",
    "        max_frame = meta.loc[i, 'MaxFr']\n",
    "        frame_list = range(len(images))\n",
    "\n",
    "        # ----> Create a DataFrame for this chamber\n",
    "        chamber_frames_df = None\n",
    "\n",
    "        # derive pos and chamber numbers robustly from folder names (no +1)\n",
    "        # If you want 1-based numbering, adjust here, but do so consciously.\n",
    "        pos_number = extract_trailing_int_from_basename(current_directory)\n",
    "        chamb_number = extract_trailing_int_from_basename(inputs_folder)\n",
    "\n",
    "        for frame_index in frame_list:\n",
    "            try:\n",
    "                if flims:\n",
    "                    fluorescence_image = imread(images_fl[frame_index])\n",
    "                    if n_channel > 2:\n",
    "                        fluorescence_image2 = imread(images_fl2[frame_index])\n",
    "\n",
    "                main_image = imread(images[frame_index])\n",
    "                normalized_image = normalize(main_image, 1, 99.8, axis=axis_norm)\n",
    "                labels, details = model.predict_instances(normalized_image, verbose=0)\n",
    "                filename_segmentation = os.path.join(outputs_folder, os.path.basename(images[frame_index]))\n",
    "                imwrite(filename_segmentation, labels, append=False, metadata=None)\n",
    "\n",
    "                region_props = regionprops_table(labels, intensity_image=fluorescence_image if flims else None, properties=prop_list)\n",
    "                if flims and n_channel > 2:\n",
    "                    region_props = add_prefix(region_props, 'fluor1')\n",
    "                    region_props2 = regionprops_table(labels, intensity_image=fluorescence_image2, properties=prop_list)\n",
    "                    region_props2 = add_prefix(region_props2, 'fluor2')\n",
    "                    for key, value in region_props2.items():\n",
    "                        if 'intensity' in key:\n",
    "                            region_props[key] = value\n",
    "\n",
    "                region_props_df = pd.DataFrame(region_props)\n",
    "\n",
    "                # Insert columns with correct values (no erroneous +1)\n",
    "                region_props_df.insert(0, 'frame', frame_index + 1)  # keep frames 1-based if desired\n",
    "                # use pos_number and chamb_number extracted from folder names\n",
    "                region_props_df.insert(0, 'pos', pos_number if pos_number is not None else meta.pos[i])\n",
    "                region_props_df.insert(0, 'replicate', meta.replicate[i])\n",
    "                # insert chamber after replicate and pos to keep a similar layout as before\n",
    "                region_props_df.insert(2, 'chamber', chamb_number if chamb_number is not None else os.path.basename(inputs_folder))\n",
    "                # use the actual chamber folder as the folder column (more precise)\n",
    "                region_props_df['folder'] = inputs_folder\n",
    "\n",
    "                if chamber_frames_df is None:\n",
    "                    chamber_frames_df = region_props_df\n",
    "                else:\n",
    "                    chamber_frames_df = pd.concat([chamber_frames_df, region_props_df], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                fails.append(f\"Error processing folder {current_directory}, Chamber {inputs_folder}, Frame {frame_index}: {e}\")\n",
    "\n",
    "        # ----> Save the DataFrame for this chamber after all frames are processed\n",
    "        if chamber_frames_df is not None:\n",
    "            # format csv filename using the extracted integers (no +1)\n",
    "            if pos_number is None:\n",
    "                pos_str = str(int(meta.pos[i])).zfill(2)\n",
    "            else:\n",
    "                pos_str = str(int(pos_number)).zfill(2)\n",
    "            if chamb_number is None:\n",
    "                # fallback: extract last two chars then zfill\n",
    "                chamb_str = os.path.basename(inputs_folder)[-2:].zfill(2)\n",
    "            else:\n",
    "                chamb_str = str(int(chamb_number)).zfill(2)\n",
    "\n",
    "            csv_filename = f\"Pos{pos_str}Chamb{chamb_str}.csv\"\n",
    "            chamber_frames_df.to_csv(os.path.join(save_directory, csv_filename), index=False)\n",
    "\n",
    "    # ----> Update metadata as before\n",
    "    meta = pd.read_csv(os.path.join(masterdir, metacsv), dtype={'stardist': str})\n",
    "    meta.at[i, 'stardist'] = 'Done'\n",
    "    if fails:\n",
    "        meta.at[i, 'stardist_fails'] = '; '.join(fails)\n",
    "    meta.to_csv(os.path.join(masterdir, metacsv), index=False)\n",
    "# --- end processing ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec376c-734f-49fc-a3f3-20565ccd7cf0",
   "metadata": {},
   "source": [
    "### DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
