{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55d75ff-0bbf-4266-aef9-f3e71ae006f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# MM pipeline: Run the StarDist2D segmentation model over all folders\n",
    "\n",
    "This notebook loads a pretrained StarDist2D segmentation model and applies the segmentation prediction on all folders within the masterfolder mainf (defined in 2nd code cell). Only microscopy chamber data containing folders should be within mainf. The segmentation is applied onto all images that end with *_PH.tif* and the segmentation image is saved into a newly created folder within each image folder named *seg_sd2*. For the moment, it assumes single-page tif files and saves single-page tif files with the exact same name as the input image used for segmentation prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be194b4",
   "metadata": {},
   "source": [
    "### Load main config file. Adapt directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6037ab35-db6c-4993-95fe-2384b76475ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:38:46.034578900Z",
     "start_time": "2026-02-10T18:38:45.966084700Z"
    }
   },
   "outputs": [],
   "source": [
    "configdir = 'C://Users/zinke/Documents/GitHub/microfluidics-image-processing/MM_pipeline';\n",
    "# uncomment the one running:\n",
    "mainconfigname = 'config_example_mixed';\n",
    "#mainconfigname = 'config_example_matched';\n",
    "\n",
    "\n",
    "if not mainconfigname.endswith('.json'):\n",
    "    mainconfigname += '.json'\n",
    "    \n",
    "if not configdir.endswith('/'):\n",
    "    configdir += '/'\n",
    "\n",
    "import json\n",
    "# Read JSON data\n",
    "with open(configdir+mainconfigname, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Assign each key-value pair as a variable\n",
    "for key, value in data.items():\n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270a2bc-943c-444b-9229-11bb2c1c965f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load various packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8362889-58a4-41ef-8062-80dbeb95f539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:38:56.266827300Z",
     "start_time": "2026-02-10T18:38:51.428552800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread, imwrite\n",
    "from datetime import datetime\n",
    "from csbdeep.utils import Path, normalize\n",
    "from skimage.measure import regionprops_table\n",
    "from skimage import io\n",
    "from skimage import segmentation\n",
    "from skimage import color\n",
    "from stardist.matching import matching_dataset\n",
    "from stardist import fill_label_holes, random_label_cmap, relabel_image_stardist, calculate_extents, gputools_available, _draw_polygons\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import re\n",
    "from pathlib import Path\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "def add_prefix(props, prefix):\n",
    "    return {f\"{prefix}_{key}\" if 'intensity' in key else key: value for key, value in props.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ae6e8-8712-4f38-9056-05fd1c397602",
   "metadata": {},
   "source": [
    "### Check if GPU can be accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fbcd94-85b0-4361-8002-31aa57e2171a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:38:59.294870500Z",
     "start_time": "2026-02-10T18:38:58.785925200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__init__.py (274): Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not find scikit-tensor which is needed for separable approximations...\n",
      "If you want to compute separable approximations, please install it with\n",
      "pip install scikit-tensor-py3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gputools_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17582b-56ed-4f81-b42c-04215b86b637",
   "metadata": {},
   "source": [
    "### Load in meta file and display head. Check if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5843fccb-8d7a-40ea-919c-2c4e49fc6d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:39:01.923712800Z",
     "start_time": "2026-02-10T18:39:01.855059800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D://Julian/agr_rev_matched/sharing/mixed\\shared_mixed_meta_processing.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>replicate</th>\n",
       "      <th>chip</th>\n",
       "      <th>pos</th>\n",
       "      <th>channel</th>\n",
       "      <th>Process</th>\n",
       "      <th>replicate2</th>\n",
       "      <th>Process2</th>\n",
       "      <th>c0_nM</th>\n",
       "      <th>c1_match_nM</th>\n",
       "      <th>...</th>\n",
       "      <th>StageY</th>\n",
       "      <th>PxinUmX</th>\n",
       "      <th>PxinUmY</th>\n",
       "      <th>register</th>\n",
       "      <th>stardist</th>\n",
       "      <th>stardist_data</th>\n",
       "      <th>stardist_fails</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_fails</th>\n",
       "      <th>stardist_data_cor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.02.2025</td>\n",
       "      <td>m06</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-38406.06</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.02.2025</td>\n",
       "      <td>m07</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-41553.46</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.02.2025</td>\n",
       "      <td>m07</td>\n",
       "      <td>c1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-37586.46</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.02.2025</td>\n",
       "      <td>m07</td>\n",
       "      <td>c1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-35631.56</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.02.2025</td>\n",
       "      <td>m07</td>\n",
       "      <td>c1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-43386.16</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date replicate chip  pos  channel  Process replicate2  Process2  \\\n",
       "7   12.02.2025       m06   c1    1        3     1718        NaN       NaN   \n",
       "8   19.02.2025       m07   c1    1        2     2129        NaN       NaN   \n",
       "9   19.02.2025       m07   c1    2        4     2142        NaN       NaN   \n",
       "10  19.02.2025       m07   c1    3        5     2151        NaN       NaN   \n",
       "11  19.02.2025       m07   c1    4        1     2173        NaN       NaN   \n",
       "\n",
       "    c0_nM  c1_match_nM  ...    StageY  PxinUmX PxinUmY  register  stardist  \\\n",
       "7       0           32  ... -38406.06    0.065   0.065      Done       NaN   \n",
       "8       0           32  ... -41553.46    0.065   0.065      Done       NaN   \n",
       "9       0           32  ... -37586.46    0.065   0.065      Done       NaN   \n",
       "10      0           32  ... -35631.56    0.065   0.065      Done       NaN   \n",
       "11      0           32  ... -43386.16    0.065   0.065      Done       NaN   \n",
       "\n",
       "    stardist_data  stardist_fails delta  delta_fails  stardist_data_cor  \n",
       "7             NaN             NaN   NaN          NaN                NaN  \n",
       "8             NaN             NaN   NaN          NaN                NaN  \n",
       "9             NaN             NaN   NaN          NaN                NaN  \n",
       "10            NaN             NaN   NaN          NaN                NaN  \n",
       "11            NaN             NaN   NaN          NaN                NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.path.join(masterdir,metacsv))\n",
    "meta = pd.read_csv(os.path.join(masterdir,metacsv), dtype={'stardist': str})\n",
    "replicates = meta.replicate.unique()\n",
    "meta.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a362e",
   "metadata": {},
   "source": [
    "### Load stardist model\n",
    "Here, the model is loaded. You need to specify the dir which contains a folder named *stardist* in the config file. This *stardist* folder needs to contain the files *weigths_best.h5* as well as the *config.json* and optionally the *thresholds.json*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3713b5-93e4-4d12-8e15-ace7422c52e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:41:08.664371200Z",
     "start_time": "2026-02-10T18:39:04.580356700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users/zinke/Documents/GitHub/microfluidics-image-processing/stardist_models/mm\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.586968, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "print(stardistmodeldir)\n",
    "model = StarDist2D(None, name='stardist', basedir=stardistmodeldir)\n",
    "axis_norm = (0,1)   # normalize channels independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a983f-591d-4329-9de0-f7351b1d17e3",
   "metadata": {},
   "source": [
    "### Define regionprops parameters. You could add more if you want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a8cea5-1872-4fcf-98d2-804f99a854fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:47:09.838175900Z",
     "start_time": "2026-02-10T18:47:09.793126100Z"
    }
   },
   "outputs": [],
   "source": [
    "if n_channel>1:\n",
    "    flims = True;\n",
    "    prop_list = ['label', \n",
    "                'area', 'centroid', \n",
    "                'axis_major_length', 'axis_minor_length',\n",
    "                 'eccentricity',\n",
    "                'intensity_mean', 'intensity_max']\n",
    "else:\n",
    "    flims = False;\n",
    "    prop_list = ['label', \n",
    "                'area', 'centroid', \n",
    "                'axis_major_length', 'axis_minor_length',\n",
    "                 'eccentricity'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31f0d9-c131-4c66-9b49-57d381335eb7",
   "metadata": {},
   "source": [
    "### Limit GPU RAM usage by StarDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbec354f-3d21-46cd-ad68-12021a62494e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:47:14.422765200Z",
     "start_time": "2026-02-10T18:47:14.369218900Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "# adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "limit_gpu_memory(fraction=ramlimit, total_memory=ramsize)\n",
    "# alternatively, try this:\n",
    "# limit_gpu_memory(None, allow_growth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c295a-9117-459c-a490-959495b3665f",
   "metadata": {},
   "source": [
    "## Main segmentation loop\n",
    "This loop goes over each row in the meta file which is marked with completed preprocessing (Progress == 'Done') and applies the StarDist segmentation model to each position/chamber iteratively. For the moment, not paralellized but could probably benefit from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6820e7d4-cfce-424b-9f53-aaa823a050ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:47:17.895160300Z",
     "start_time": "2026-02-10T18:47:17.872149900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Patch Keras model's predict to always use verbose=0\n",
    "orig_predict = model.keras_model.predict\n",
    "def predict_no_verbose(*args, **kwargs):\n",
    "    kwargs['verbose'] = 0\n",
    "    return orig_predict(*args, **kwargs)\n",
    "model.keras_model.predict = predict_no_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6cfbbe4-bdc9-442a-a1eb-226439f5fcfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:47:19.580915700Z",
     "start_time": "2026-02-10T18:47:19.549771200Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper to robustly extract trailing integer from a path basename\n",
    "def extract_trailing_int_from_basename(path):\n",
    "    name = os.path.basename(path)\n",
    "    m = re.search(r'(\\d+)$', name)\n",
    "    return int(m.group(1)) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f852a07c-a070-4f8e-b21e-df10d0fc29e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T19:13:45.725516400Z",
     "start_time": "2026-02-10T18:47:21.827825400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m01, Pos 01: 100%|█████████████████████████████████████████████████████████████████████| 42/42 [11:30<00:00, 16.43s/it]\n",
      "m01, Pos 02: 100%|█████████████████████████████████████████████████████████████████████| 47/47 [18:58<00:00, 24.22s/it]\n",
      "m03, Pos 01: 100%|█████████████████████████████████████████████████████████████████████| 48/48 [18:38<00:00, 23.30s/it]\n",
      "m03, Pos 02: 100%|█████████████████████████████████████████████████████████████████████| 40/40 [14:05<00:00, 21.14s/it]\n",
      "m03, Pos 03: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [14:19<00:00, 20.97s/it]\n",
      "m03, Pos 04: 100%|█████████████████████████████████████████████████████████████████████| 21/21 [07:37<00:00, 21.77s/it]\n",
      "m06, Pos 01: 100%|█████████████████████████████████████████████████████████████████████| 34/34 [14:25<00:00, 25.45s/it]\n",
      "m07, Pos 01: 100%|█████████████████████████████████████████████████████████████████████| 34/34 [14:37<00:00, 25.81s/it]\n",
      "m07, Pos 02: 100%|█████████████████████████████████████████████████████████████████████| 37/37 [14:06<00:00, 22.87s/it]\n",
      "m07, Pos 03: 100%|█████████████████████████████████████████████████████████████████████| 33/33 [15:46<00:00, 28.67s/it]\n",
      "m07, Pos 04: 100%|█████████████████████████████████████████████████████████████████████| 40/40 [17:45<00:00, 26.63s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, meta.shape[0]):\n",
    "    # reload metadata each iteration if you need the file updated by others,\n",
    "    # otherwise you can read once before the loop for speed.\n",
    "    meta = pd.read_csv(os.path.join(masterdir, metacsv), dtype={'stardist': str, 'stardist_data': str})\n",
    "\n",
    "    if meta.loc[i, 'stardist'] == 'Done' or meta.loc[i, 'Exclude'] == 'excl' or not meta.loc[i, ('register')] == 'Done':\n",
    "        continue\n",
    "\n",
    "    main_folder = os.path.join(masterdir, savedirname, meta.replicate[i], 'Chambers')\n",
    "    save_directory = os.path.join(main_folder, 'stardist2')\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    current_directory = os.path.join(main_folder, f'Pos{str(meta.pos[i]).zfill(2)}')\n",
    "    if not os.path.exists(current_directory):\n",
    "        print(current_directory + ' not found')\n",
    "        continue\n",
    "\n",
    "    chambf = [f.path for f in os.scandir(current_directory) if f.is_dir()]\n",
    "    chambf = [k for k in chambf if 'Chamb' in k]\n",
    "\n",
    "    fails = []\n",
    "\n",
    "    for chambi in tqdm(range(0, len(chambf)), desc=meta.replicate[i] + ', Pos ' + str(meta.pos[i]).zfill(2)):\n",
    "        inputs_folder = chambf[chambi]\n",
    "        outputs_folder = os.path.join(inputs_folder, \"seg_sd2\")\n",
    "        os.makedirs(outputs_folder, exist_ok=True)\n",
    "        for file in Path(outputs_folder).glob('*tif'):\n",
    "            os.remove(file)\n",
    "\n",
    "        images = sorted(Path(inputs_folder).glob('*Ch1*tif'))\n",
    "        if flims:\n",
    "            images_fl = sorted(Path(inputs_folder).glob('*Ch2*tif'))\n",
    "            if n_channel > 2:\n",
    "                images_fl2 = sorted(Path(inputs_folder).glob('*Ch3*tif'))\n",
    "\n",
    "        max_frame = meta.loc[i, 'MaxFr']\n",
    "        frame_list = range(len(images))\n",
    "\n",
    "        # ----> Create a DataFrame for this chamber\n",
    "        chamber_frames_df = None\n",
    "\n",
    "        # derive pos and chamber numbers robustly from folder names (no +1)\n",
    "        # If you want 1-based numbering, adjust here, but do so consciously.\n",
    "        pos_number = extract_trailing_int_from_basename(current_directory)\n",
    "        chamb_number = extract_trailing_int_from_basename(inputs_folder)\n",
    "\n",
    "        for frame_index in frame_list:\n",
    "            try:\n",
    "                if flims:\n",
    "                    fluorescence_image = imread(images_fl[frame_index])\n",
    "                    if n_channel > 2:\n",
    "                        fluorescence_image2 = imread(images_fl2[frame_index])\n",
    "\n",
    "                main_image = imread(images[frame_index])\n",
    "                normalized_image = normalize(main_image, 1, 99.8, axis=axis_norm)\n",
    "                labels, details = model.predict_instances(normalized_image, verbose=0)\n",
    "                filename_segmentation = os.path.join(outputs_folder, os.path.basename(images[frame_index]))\n",
    "                imwrite(filename_segmentation, labels, append=False, metadata=None)\n",
    "\n",
    "                region_props = regionprops_table(labels, intensity_image=fluorescence_image if flims else None, properties=prop_list)\n",
    "                if flims and n_channel > 2:\n",
    "                    region_props = add_prefix(region_props, 'fluor1')\n",
    "                    region_props2 = regionprops_table(labels, intensity_image=fluorescence_image2, properties=prop_list)\n",
    "                    region_props2 = add_prefix(region_props2, 'fluor2')\n",
    "                    for key, value in region_props2.items():\n",
    "                        if 'intensity' in key:\n",
    "                            region_props[key] = value\n",
    "\n",
    "                region_props_df = pd.DataFrame(region_props)\n",
    "\n",
    "                # Insert columns with correct values (no erroneous +1)\n",
    "                region_props_df.insert(0, 'frame', frame_index + 1)  # keep frames 1-based if desired\n",
    "                # use pos_number and chamb_number extracted from folder names\n",
    "                region_props_df.insert(0, 'pos', pos_number if pos_number is not None else meta.pos[i])\n",
    "                region_props_df.insert(0, 'replicate', meta.replicate[i])\n",
    "                # insert chamber after replicate and pos to keep a similar layout as before\n",
    "                region_props_df.insert(2, 'chamber', chamb_number if chamb_number is not None else os.path.basename(inputs_folder))\n",
    "                # use the actual chamber folder as the folder column (more precise)\n",
    "                region_props_df['folder'] = inputs_folder\n",
    "\n",
    "                if chamber_frames_df is None:\n",
    "                    chamber_frames_df = region_props_df\n",
    "                else:\n",
    "                    chamber_frames_df = pd.concat([chamber_frames_df, region_props_df], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                fails.append(f\"Error processing folder {current_directory}, Chamber {inputs_folder}, Frame {frame_index}: {e}\")\n",
    "\n",
    "        # ----> Save the DataFrame for this chamber after all frames are processed\n",
    "        if chamber_frames_df is not None:\n",
    "            # format csv filename using the extracted integers (no +1)\n",
    "            if pos_number is None:\n",
    "                pos_str = str(int(meta.pos[i])).zfill(2)\n",
    "            else:\n",
    "                pos_str = str(int(pos_number)).zfill(2)\n",
    "            if chamb_number is None:\n",
    "                # fallback: extract last two chars then zfill\n",
    "                chamb_str = os.path.basename(inputs_folder)[-2:].zfill(2)\n",
    "            else:\n",
    "                chamb_str = str(int(chamb_number)).zfill(2)\n",
    "\n",
    "            csv_filename = f\"Pos{pos_str}Chamb{chamb_str}.csv\"\n",
    "            chamber_frames_df.to_csv(os.path.join(save_directory, csv_filename), index=False)\n",
    "\n",
    "    # ----> Update metadata as before\n",
    "    meta = pd.read_csv(os.path.join(masterdir, metacsv), dtype={'stardist': str})\n",
    "    meta.at[i, 'stardist'] = 'Done'\n",
    "    if fails:\n",
    "        meta.at[i, 'stardist_fails'] = '; '.join(fails)\n",
    "    meta.to_csv(os.path.join(masterdir, metacsv), index=False)\n",
    "# --- end processing ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec376c-734f-49fc-a3f3-20565ccd7cf0",
   "metadata": {},
   "source": [
    "### DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
